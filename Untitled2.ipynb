{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNgKdCqGQuHqU6dVOnceFl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishitha24/ImageCaptioning/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz8R08VkHMMw",
        "outputId": "43ae773b-d072-4fca-f47f-1db1ede141cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flask-ngrok\n",
            "  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.2)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Installing collected packages: flask-ngrok\n",
            "Successfully installed flask-ngrok-0.0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvnnL5lyMSsV"
      },
      "source": [
        "from flask import Flask, render_template, request\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.applications import ResNet50\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
        "from keras.models import Sequential, Model\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing import image, sequence\n",
        "import cv2\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RwKgJxNMXT5",
        "outputId": "d6b8e811-f353-43e8-a68e-42273fc9d9de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab = np.load('vocab.npy', allow_pickle=True)\n",
        "\n",
        "vocab = vocab.item()\n",
        "\n",
        "inv_vocab = {v:k for k,v in vocab.items()}\n",
        "\n",
        "\n",
        "print(\"+\"*50)\n",
        "print(\"vocabulary loaded\")"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "vocabulary loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSm3SMubMo1z"
      },
      "source": [
        "embedding_size = 128\n",
        "vocab_size = len(vocab)\n",
        "max_len = 40\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5STkFKVIMroQ",
        "outputId": "c98b6944-3b45-43a1-d493-a3abda635b90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "image_model = Sequential()\n",
        "\n",
        "image_model.add(Dense(embedding_size, input_shape=(2048,), activation='relu'))\n",
        "image_model.add(RepeatVector(max_len))\n",
        "\n",
        "\n",
        "language_model = Sequential()\n",
        "\n",
        "language_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=max_len))\n",
        "language_model.add(LSTM(256, return_sequences=True))\n",
        "language_model.add(TimeDistributed(Dense(embedding_size)))\n",
        "\n",
        "\n",
        "conca = Concatenate()([image_model.output, language_model.output])\n",
        "x = LSTM(128, return_sequences=True)(conca)\n",
        "x = LSTM(512, return_sequences=False)(x)\n",
        "x = Dense(vocab_size)(x)\n",
        "out = Activation('softmax')(x)\n",
        "model = Model(inputs=[image_model.input, language_model.input], outputs = out)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\n",
        "model.load_weights('mine_model_weights.h5')\n",
        "\n",
        "print(\"=\"*150)\n",
        "print(\"MODEL LOADED\")\n",
        "\n",
        "resnet = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')\n",
        "\n",
        "\n",
        "print(\"=\"*150)\n",
        "print(\"RESNET MODEL LOADED\")\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "======================================================================================================================================================\n",
            "MODEL LOADED\n",
            "======================================================================================================================================================\n",
            "RESNET MODEL LOADED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvviWgV4TdUX"
      },
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 1\n",
        "\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/after', methods=['GET', 'POST'])\n",
        "def after():\n",
        "\n",
        "    global model, resnet, vocab, inv_vocab\n",
        "\n",
        "    img = request.files['file1']\n",
        "\n",
        "    img.save('static/file.jpg')\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"IMAGE SAVED\")\n",
        "\n",
        "\n",
        "    \n",
        "    image = cv2.imread('static/file.jpg')\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    image = cv2.resize(image, (224,224))\n",
        "\n",
        "    image = np.reshape(image, (1,224,224,3))    \n",
        "    \n",
        "    incept = resnet.predict(image).reshape(1,2048)\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"Predict Features\")\n",
        "\n",
        "\n",
        "    text_in = ['startofseq']\n",
        "\n",
        "    final = ''\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"GETING Captions\")\n",
        "\n",
        "    count = 0\n",
        "    while tqdm(count < 20):\n",
        "\n",
        "        count += 1\n",
        "\n",
        "        encoded = []\n",
        "        for i in text_in:\n",
        "            encoded.append(vocab[i])\n",
        "\n",
        "        padded = pad_sequences([encoded], maxlen=max_len, padding='post', truncating='post').reshape(1,max_len)\n",
        "\n",
        "        sampled_index = np.argmax(model.predict([incept, padded]))\n",
        "\n",
        "        sampled_word = inv_vocab[sampled_index]\n",
        "\n",
        "        if sampled_word != 'endofseq':\n",
        "            final = final + ' ' + sampled_word\n",
        "\n",
        "        text_in.append(sampled_word)\n",
        "        print(final)\n",
        "\n",
        "    return render_template(\"after.html\", data=final)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YN5A9NeUtH5",
        "outputId": "8c7d6c7f-6d41-420e-8f07-a8899107028c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    app.run()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n",
            " * Running on http://473ce0a455ca.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [16/Nov/2020 10:35:51] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [16/Nov/2020 10:35:51] \"\u001b[33mGET /static/styles.css HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [16/Nov/2020 10:35:52] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "[2020-11-16 10:35:59,155] ERROR in app: Exception on /after [POST]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1952, in full_dispatch_request\n",
            "    rv = self.handle_user_exception(e)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1821, in handle_user_exception\n",
            "    reraise(exc_type, exc_value, tb)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/_compat.py\", line 39, in reraise\n",
            "    raise value\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1950, in full_dispatch_request\n",
            "    rv = self.dispatch_request()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/flask/app.py\", line 1936, in dispatch_request\n",
            "    return self.view_functions[rule.endpoint](**req.view_args)\n",
            "  File \"<ipython-input-64-ac9f3f8dc7f2>\", line 25, in after\n",
            "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
            "cv2.error: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
            "\n",
            "127.0.0.1 - - [16/Nov/2020 10:35:59] \"\u001b[35m\u001b[1mPOST /after HTTP/1.1\u001b[0m\" 500 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "IMAGE SAVED\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}